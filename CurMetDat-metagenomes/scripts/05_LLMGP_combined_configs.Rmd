---
title: "LLMGP samples and config files"
output: html_notebook
---

# Init
```{r}
library(tidyverse)
library(glue)
```

# Var
```{r}
#Out dir
combined_dir = "/ebio/abt3_projects/databases_no-backup/curatedMetagenomicData/global_metagenomes/combined_GTDBr86"
pipeline_folder = "/ebio/abt3_projects/small_projects/jdelacuesta/llmgp_r86"
```

## Load individual sample files
```{r}
# Unspring files
unspring_dir = "/ebio/abt3_scratch/jdelacuesta/unspring/reads"
unspring_samplefiles = list.files(unspring_dir, recursive = F) %>% 
  file.path(unspring_dir, ., "final/samples.txt")

unspring_df_raw = map_df(unspring_samplefiles, function(x) read_delim(x, delim = "\t"))

unspring_df = unspring_df_raw %>% 
  mutate(Read1 = str_replace(Read1, "/ebio/abt3_projects/databases_no-backup/curatedMetagenomicData/global_metagenomes/LLMGQC/", "/ebio/abt3_scratch/jdelacuesta/unspring/reads/")) %>% 
  select(-Read2)

unspring_df %>% head
```

```{r}
#Taichi's eco-evo
ecoevo_dir = "/ebio/abt3_projects/databases_no-backup/Taichi_h-m-coevo/LLMGQC"
ecoevo_samplefiles = list.files(ecoevo_dir, recursive = F) %>% 
  .[str_which(., "PRJ")] %>% 
  file.path(ecoevo_dir, ., "final/samples.txt")

ecoevo_df_raw = map_df(ecoevo_samplefiles, function(x) read_delim(x, delim = "\t"))

ecoevo_df = ecoevo_df_raw %>% 
  select(-Read2)

ecoevo_df %>% head
```

```{r}
# Visconti
Visconti_dir = "/ebio/abt3_projects/databases_no-backup/TUK/metagenome/Visconti2019/LLMGQC/final"
Visconti_samplefiles = file.path(Visconti_dir, "/samples.txt")

Visconti_df_raw = map_df(Visconti_samplefiles, function(x) read_delim(x, delim = "\t"))

Visconti_df = Visconti_df_raw %>% 
  filter(!is.na(Read1)) %>% 
  select(-Read2)

Visconti_df %>% head
```

```{r}
# HuBif1
HuBif1_dir = "/ebio/abt3_projects/HUBIF_metagenomics/llmgqc/LLMGQC_noconvert_output/final"
HuBif2_dir = "/ebio/abt3_projects/HUBIF_metagenomics/llmgqc/LLMGQC_output_reseqs/final"

HuBif_samplefiles = file.path(c(HuBif1_dir, HuBif2_dir), "samples.txt")

HuBif_df_raw = map_df(HuBif_samplefiles, function(x) read_delim(x, delim = "\t")) 

HuBif_df = HuBif_df_raw %>% 
  select(-Read2) %>% 
  filter(str_detect(Sample, "^[GTV]"), !str_detect(Sample, "saliva")) %>% 
  mutate(Sample = str_remove(Sample, "\\_[0-9]$")) %>% 
  arrange(Sample)
```

## Combine tables
```{r}
# Combine tables and remove NAs
Combined_df = bind_rows(list(Visconti_df, ecoevo_df, unspring_df, HuBif_df)) %>%
  filter(!is.na(Read1))

Combined_samplesfile = file.path(combined_dir, "configs", "combined_samples.txt")
write_delim(Combined_df, path = Combined_samplesfile, delim = "\t")
```

# LLMGP config file
```{r}
config_text = '# DESCRIPTION:
## This is an example of running the pipeline with a custom humann2 db.
## This config is set up to just use the custom nucleotide db, but the protein db could be used also (or instead)

#-- I/O --#
# table with sample --> read_file information
samples_file: {samples_file}

# output location
output_dir: {output_dir}

# temporary file directory (your username will be added automatically)
tmp_dir: /ebio/abt3_scratch/

# read file path
# use None if full file path is included in the samples_file
read_file_path: None

#-- DB --#
## humann2 
### custom humann2 databases
humann2_nuc_db: /ebio/abt3_projects/databases_no-backup/GTDB/release86/LLMGP-DB/humann2/all_genes_annot.fna.gz
humann2_prot_db: /ebio/abt3_projects/databases_no-backup/GTDB/release86/LLMGP-DB/humann2/all_genes.dmnd
### required humann2 database files (no need to change this)
genefamily_annotation_db: /ebio/abt3_projects/databases_no-backup/humann2/utility_mapping/map_uniref50_name.txt.bz2
metaphlan2_pkl_db: /ebio/abt3_projects/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200.pkl
metaphlan2_bt2_db: /ebio/abt3_projects/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200
utility_mapping_db: /ebio/abt3_projects/databases_no-backup/humann2/utility_mapping
## kraken/bracken (db selected automatically based on read length)
kraken_dbs:
  150bp: /ebio/abt3_projects/databases_no-backup/GTDB/release86/LLMGP-DB/kraken2/database150mers.kraken
  100bp: /ebio/abt3_projects/databases_no-backup/GTDB/release86/LLMGP-DB/kraken2/database100mers.kraken
### NCBI taxonomy
tax_dump: /ebio/abt3_projects/databases/Kraken/K2_GTDB/Kraken/taxonomy/names.dmp

#-- subsample --#
# subsampling input reads 
## Skip skips subsampling; otherwise set the number of reads to subsample
subsample_depth: Skip   
subsample_seed: 18938

#-- include read2 (if paired-end) --#
# combine R1 & R2 or just use R1?
include_read2: False

#-- humann2 temporary files --#
# remove the large temporary files generated by humann2?
rm_humann2_tmp_files: True      

#-- humann2 groupings --#
# always have at least the "*_default" grouping
humann2_regroup:
  - uniref50_default
  - uniref50_go
  - uniref50_ko
  - uniref50_eggnog
  - uniref50_pfam
  - uniref50_level4ec
  - uniref50_infogo1000
  - uniref50_rxn

#-- software parameters --#
# Use Skip to skip steps.
# By skipping, you can run just humann2, kraken/bracken, or simka
params:
  # humann2
  metaphlan2: Skip # -t rel_ab  
  humann2: Skip # --gap-fill on --bypass-nucleotide-index --diamond-2pass
  humann2_db_in_memory: True        # copy databases to memory; less I/O, more memory
  humann2_diamond: --sensitive --max-target-seqs 3 --block-size 4 --index-chunks 1
  humann2_diamond_evalue: 0.001
  reduce_taxonomic_profile: --function max --sort-by level
  humann2_renorm_table: --units relab
  # kraken/bracken (NOTE: dependent on read length)
  kraken: ""
  bracken: -t 100 -l S        # species level (S); `-r` parameter set automatically
  # simka 
  simka: Skip #-kmer-size 31 -abundance-min 2 -simple-dist -max-reads 1000000
  simka_vis: -width 8 -height 8 -pca -heatmap
  # hulk
  hulk_histosketch: Skip #-k 21 -m 2
  hulk_distance: 
    - jaccard
    - braycurtis


#-- snakemake pipeline --#
pipeline:
  snakemake_folder: ./
  script_folder: ./bin/scripts/
'
```

```{r}
config_file = file.path(combined_dir, "configs", "config_GTDBr86.txt")

config_GTDBr86 = glue(config_text, 
                      samples_file = Combined_samplesfile,
                      output_dir = file.path(combined_dir, "profiles"))


write_lines(config_GTDBr86, path = config_file)
```

# Execute pipeline
```{r}
conda_env = 'source activate snakemake'
SGE_out_dir = file.path(pipeline_folder, "tmp/SGE_out")
profile_cmd = "cd {llmgp}; {conda_env}; screen -L -S llmgp_r86 {exe} {config} {jobs} --keep-going --rerun-incomplete --dryrun"
profile_job = glue(profile_cmd, 
              conda_env = conda_env, 
              llmgp = pipeline_folder, 
              exe = './snakemake_sge.sh', 
              config = config_file,
              jobs = 40)
profile_job 
```

# Combined tax profile





